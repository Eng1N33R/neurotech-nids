# Training module
#
# This module trains the neural network on a dataset. Designed
# to be used with the base dataset and datasets generated by
# the learn module.

import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'
import tensorflow as tf
import numpy as np
import argparse
import sys

parser = argparse.ArgumentParser(description='NeuroTech training module.')
parser.add_argument('-d', '--dataset', type=str, default="data/merged.training.contrib.csv", help='specify the data set to train on (default data/merged.training.contrib.csv).')
parser.add_argument('-s', '--steps', type=int, default=8192, help='specify the number of steps to fit the model over (default 8192).')
args = parser.parse_args()

print("Training on " + args.dataset + " over " + str(args.steps) + " steps")

TRAFFIC_TRAINING = os.path.join(os.path.dirname(__file__), args.dataset)

training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
    filename=TRAFFIC_TRAINING,
    target_dtype=np.int,
    features_dtype=np.float32,
    target_column=9)

# Specify that all features have real-value data
feature_columns = [tf.contrib.layers.real_valued_column("", dimension=9)]

# Build 3 layer DNN with 10, 20, 10 units respectively.
classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                            hidden_units=[10, 20, 10],
                                            n_classes=2,
                                            model_dir="data/traffic_model")
# Define the training inputs
def get_train_inputs():
    x = tf.constant(training_set.data)
    y = tf.constant(training_set.target)

    return x, y

# Fit model.
classifier.fit(input_fn=get_train_inputs, steps=args.steps)
